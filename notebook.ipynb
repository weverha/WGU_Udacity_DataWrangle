{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_FILE = \"WPM.osm\"  \n",
    "SAMPLE_FILE = \"sample_WPM.osm\"\n",
    "\n",
    "# Parameter: take every k-th top level element\n",
    "k = 42\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 33,\n",
      " 'nd': 10707,\n",
      " 'node': 9373,\n",
      " 'osm': 1,\n",
      " 'relation': 4,\n",
      " 'tag': 3130,\n",
      " 'way': 632}\n"
     ]
    }
   ],
   "source": [
    "# Finding out what tags there are and how many of each\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', )):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('sample_WPM.osm')\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 84411, 'lower_colon': 20640, 'other': 25527, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "# Checking \"k\" value for each tag and looking for potential problems\n",
    "\n",
    "# 3 regular expressions I used to check for patterns in tags\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "# Checking for problematic characters\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Changing the data model into a dictionary\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:    \n",
    "            keys['other'] += 1  \n",
    "#           print element.attrib['k']\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_keys_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    keys = process_keys_map(OSM_FILE)\n",
    "    pprint.pprint(keys)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique keys (tag attrib['k'])is 257\n",
      "['access',\n",
      " 'addr:city',\n",
      " 'addr:country',\n",
      " 'addr:housenumber',\n",
      " 'addr:postcode',\n",
      " 'addr:state',\n",
      " 'addr:street',\n",
      " 'addr:unit',\n",
      " 'admin_level',\n",
      " 'aeroway',\n",
      " 'agricultural',\n",
      " 'alt_name',\n",
      " 'amenity',\n",
      " 'area',\n",
      " 'atm',\n",
      " 'attribution',\n",
      " 'barrier',\n",
      " 'bench',\n",
      " 'bicycle',\n",
      " 'boundary',\n",
      " 'boundary_type',\n",
      " 'brand',\n",
      " 'brand:wikidata',\n",
      " 'brand:wikipedia',\n",
      " 'bridge',\n",
      " 'building',\n",
      " 'building:levels',\n",
      " 'cables',\n",
      " 'capacity',\n",
      " 'changing_table',\n",
      " 'changing_table:location',\n",
      " 'circuits',\n",
      " 'clothes',\n",
      " 'colour',\n",
      " 'condition',\n",
      " 'contact:email',\n",
      " 'contact:website',\n",
      " 'covered',\n",
      " 'craft',\n",
      " 'created_by',\n",
      " 'cuisine',\n",
      " 'cycleway:both',\n",
      " 'cycleway:right',\n",
      " 'destination',\n",
      " 'destination:ref',\n",
      " 'destination:street',\n",
      " 'dispensing',\n",
      " 'ele',\n",
      " 'emergency',\n",
      " 'entrance',\n",
      " 'expressway',\n",
      " 'faa',\n",
      " 'fee',\n",
      " 'fire_hydrant:position',\n",
      " 'fire_hydrant:type',\n",
      " 'foot',\n",
      " 'frequency',\n",
      " 'generator:method',\n",
      " 'generator:source',\n",
      " 'gnis:Class',\n",
      " 'gnis:County',\n",
      " 'gnis:County_num',\n",
      " 'gnis:ST_alpha',\n",
      " 'gnis:ST_num',\n",
      " 'gnis:county_id',\n",
      " 'gnis:county_name',\n",
      " 'gnis:created',\n",
      " 'gnis:feature_id',\n",
      " 'gnis:feature_type',\n",
      " 'gnis:id',\n",
      " 'gnis:import_uuid',\n",
      " 'gnis:reviewed',\n",
      " 'gnis:state_id',\n",
      " 'golf',\n",
      " 'grades',\n",
      " 'handicap',\n",
      " 'healthcare',\n",
      " 'hgv',\n",
      " 'highway',\n",
      " 'historic',\n",
      " 'historical',\n",
      " 'horse',\n",
      " 'import_uuid',\n",
      " 'incline',\n",
      " 'indoor',\n",
      " 'intermittent',\n",
      " 'internet_access',\n",
      " 'internet_access:fee',\n",
      " 'is_in',\n",
      " 'junction:ref',\n",
      " 'jurisdiction',\n",
      " 'landuse',\n",
      " 'lanes',\n",
      " 'layer',\n",
      " 'leaf_type',\n",
      " 'leisure',\n",
      " 'length',\n",
      " 'level',\n",
      " 'lit',\n",
      " 'location',\n",
      " 'man_made',\n",
      " 'maritime',\n",
      " 'massgis:ALT_SITE_N',\n",
      " 'massgis:ARTICLE97',\n",
      " 'massgis:ASSESS_ACR',\n",
      " 'massgis:ASSESS_BLK',\n",
      " 'massgis:ASSESS_LOT',\n",
      " 'massgis:ASSESS_MAP',\n",
      " 'massgis:ASSESS_SUB',\n",
      " 'massgis:ATT_DATE',\n",
      " 'massgis:BASE_MAP',\n",
      " 'massgis:BOND_ACCT',\n",
      " 'massgis:CAL_DATE_R',\n",
      " 'massgis:COMMENTS',\n",
      " 'massgis:DCAM_ID',\n",
      " 'massgis:DEED_ACRES',\n",
      " 'massgis:EOEAINVOLV',\n",
      " 'massgis:FEESYM',\n",
      " 'massgis:FEE_OWNER',\n",
      " 'massgis:FY_FUNDING',\n",
      " 'massgis:GRANTPROG1',\n",
      " 'massgis:GRANTTYPE1',\n",
      " 'massgis:INTSYM',\n",
      " 'massgis:IT_VALC',\n",
      " 'massgis:IT_VALDESC',\n",
      " 'massgis:LEV_PROT',\n",
      " 'massgis:LOC_ID',\n",
      " 'massgis:MANAGER',\n",
      " 'massgis:MANAGR_ABR',\n",
      " 'massgis:MANAGR_TYP',\n",
      " 'massgis:OBJECTID',\n",
      " 'massgis:OLI_1_ABRV',\n",
      " 'massgis:OLI_1_INT',\n",
      " 'massgis:OLI_1_ORG',\n",
      " 'massgis:OLI_1_TYPE',\n",
      " 'massgis:OLI_2_ABRV',\n",
      " 'massgis:OLI_2_INT',\n",
      " 'massgis:OLI_2_ORG',\n",
      " 'massgis:OLI_2_TYPE',\n",
      " 'massgis:OS_DEED_BO',\n",
      " 'massgis:OS_DEED_PA',\n",
      " 'massgis:OS_ID',\n",
      " 'massgis:OWNER_ABRV',\n",
      " 'massgis:OWNER_TYPE',\n",
      " 'massgis:PALIS_ID',\n",
      " 'massgis:POLY_CODE',\n",
      " 'massgis:POLY_ID',\n",
      " 'massgis:PRIM_PURP',\n",
      " 'massgis:PROJ_ID1',\n",
      " 'massgis:PROJ_ID2',\n",
      " 'massgis:PUB_ACCESS',\n",
      " 'massgis:SITE_NAME',\n",
      " 'massgis:SOURCE',\n",
      " 'massgis:SOURCE_MAP',\n",
      " 'massgis:SOURCE_SCA',\n",
      " 'massgis:SOURCE_TYP',\n",
      " 'massgis:TOWN_ID',\n",
      " 'massgis:WETCODE',\n",
      " 'massgis:school_id',\n",
      " 'massgis:way_id',\n",
      " 'material',\n",
      " 'maxspeed',\n",
      " 'maxspeed:advisory',\n",
      " 'motor_vehicle',\n",
      " 'name',\n",
      " 'name:en',\n",
      " 'natural',\n",
      " 'noexit',\n",
      " 'noref',\n",
      " 'note',\n",
      " 'office',\n",
      " 'official_name',\n",
      " 'old_name',\n",
      " 'oneway',\n",
      " 'opening_hours',\n",
      " 'opening_hours:covid19',\n",
      " 'operator',\n",
      " 'orig_name',\n",
      " 'owner',\n",
      " 'ownership',\n",
      " 'par',\n",
      " 'park_ride',\n",
      " 'parking',\n",
      " 'payment',\n",
      " 'phone',\n",
      " 'place',\n",
      " 'plant:method',\n",
      " 'plant:output:electricity',\n",
      " 'plant:source',\n",
      " 'playground',\n",
      " 'population',\n",
      " 'power',\n",
      " 'product',\n",
      " 'protect_class',\n",
      " 'protected',\n",
      " 'protection_title',\n",
      " 'public_transport',\n",
      " 'railway',\n",
      " 'ramp',\n",
      " 'ref',\n",
      " 'ref:nrhp',\n",
      " 'ref:walmart',\n",
      " 'region',\n",
      " 'religion',\n",
      " 'roof:levels',\n",
      " 'roof:shape',\n",
      " 'sac_scale',\n",
      " 'sand',\n",
      " 'screen',\n",
      " 'service',\n",
      " 'shelter',\n",
      " 'shop',\n",
      " 'sidewalk',\n",
      " 'smoking',\n",
      " 'source',\n",
      " 'source:hgv',\n",
      " 'source:maxspeed',\n",
      " 'source:name',\n",
      " 'source:url',\n",
      " 'source_url',\n",
      " 'sport',\n",
      " 'start_date',\n",
      " 'substance',\n",
      " 'substation',\n",
      " 'supervised',\n",
      " 'surface',\n",
      " 'takeaway',\n",
      " 'tidal',\n",
      " 'tiger:cfcc',\n",
      " 'tiger:name_base',\n",
      " 'tiger:name_base_1',\n",
      " 'tiger:name_direction_prefix',\n",
      " 'tiger:name_direction_suffix',\n",
      " 'tiger:name_type',\n",
      " 'tiger:name_type_1',\n",
      " 'tiger:reviewed',\n",
      " 'toilets',\n",
      " 'tourism',\n",
      " 'tower:type',\n",
      " 'traffic_calming',\n",
      " 'traffic_sign',\n",
      " 'traffic_signals',\n",
      " 'traffic_signals:direction',\n",
      " 'tunnel',\n",
      " 'turn:lanes',\n",
      " 'type',\n",
      " 'voltage',\n",
      " 'wall',\n",
      " 'water',\n",
      " 'waterway',\n",
      " 'website',\n",
      " 'wetland',\n",
      " 'wheelchair',\n",
      " 'width',\n",
      " 'wikidata',\n",
      " 'wikipedia']\n"
     ]
    }
   ],
   "source": [
    "# Finding unique k (tag attrib['k']) and count\n",
    "\n",
    "def unique_keys(filename):\n",
    "    distinct_keys=[]\n",
    "    count=1\n",
    "\n",
    "    EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "    for element in EL:\n",
    "        if element.tag=='node' or element.tag=='way':\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k'] not in distinct_keys:\n",
    "                    distinct_keys.append(tag.attrib['k'])\n",
    "                    count+=1\n",
    "    distinct_keys.sort()\n",
    "    print(\"Total number of unique keys (tag attrib['k'])is {}\".format(count))\n",
    "    \n",
    "#    return distinct_keys\n",
    "      \n",
    "    pprint.pprint(distinct_keys) # looks cleaner this way\n",
    "    \n",
    "                \n",
    "#unique_keys(SAMPLE_FILE)  # Using Sample file as input to audit the addr:street key\n",
    "unique_keys(OSM_FILE)  \n",
    "#I used the sample file first and I became more curious and took a look at the whole file since it was not that big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:street\n",
      "['State Road',\n",
      " 'Potomska Road',\n",
      " 'Faunce Corner Mall Road',\n",
      " 'Rock Odundee Road',\n",
      " 'Faunce Corner Road',\n",
      " 'Shaker Road',\n",
      " 'Howland Mill Lane',\n",
      " 'South Brown Street',\n",
      " 'Hixville Road',\n",
      " 'Bellevue Street',\n",
      " 'Green Drive',\n",
      " 'Emmett Avenue',\n",
      " 'Cross Road',\n",
      " 'Elliot Street',\n",
      " 'Rockville Avenue',\n",
      " 'Gaffney Road',\n",
      " 'Greystone Avenue',\n",
      " 'Gaffney Road',\n",
      " 'Cedar Avenue',\n",
      " 'Juliette Street',\n",
      " 'State Road',\n",
      " 'State Road',\n",
      " 'Old Westport Road',\n",
      " 'Chase Road',\n",
      " 'Longmeadow Road',\n",
      " 'Chase Road',\n",
      " 'Barneys Joy Road',\n",
      " 'Azalea Drive',\n",
      " 'Cross Road',\n",
      " 'State Road',\n",
      " 'Duane Avenue',\n",
      " 'Yorke Street',\n",
      " 'Horseneck Road',\n",
      " 'Morton Avenue',\n",
      " 'Yorke Street',\n",
      " 'Hancock Street',\n",
      " 'Fisher Road',\n",
      " 'Woodcock Road',\n",
      " 'Woodcock Road',\n",
      " 'Elswick Street',\n",
      " 'Hillcrest Street',\n",
      " 'Lucy Little Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Slades Corner Road',\n",
      " 'Horseneck Road',\n",
      " 'Slades Farm Lane',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Christine Drive',\n",
      " 'Fisher Road',\n",
      " 'Eliza Lane',\n",
      " 'Red Oak Lane',\n",
      " 'Fisher Road',\n",
      " 'Fisher Pines Way',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Red Oak Lane',\n",
      " 'Division Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Reed Road',\n",
      " 'State Road',\n",
      " 'Sherbrooke Road',\n",
      " 'Sherbrooke Road',\n",
      " 'Lakewood Road',\n",
      " 'Lake Avenue',\n",
      " 'Line Road',\n",
      " 'East King Road',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Horseneck Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Autumn Drive',\n",
      " 'Beeden Road',\n",
      " 'Autumn Drive',\n",
      " 'Horseneck Road',\n",
      " 'Pettey Lane',\n",
      " 'Miss Rachel Trail',\n",
      " 'Old County Road',\n",
      " 'American Legion Highway',\n",
      " 'Reed Road',\n",
      " 'Lincoln Avenue',\n",
      " 'Reed Road',\n",
      " 'Reed Road',\n",
      " 'Highridge Road',\n",
      " 'Pine Hill Road',\n",
      " 'Shady Lane',\n",
      " 'Highland Avenue',\n",
      " 'Cummings Lane',\n",
      " 'Westlook Lane',\n",
      " 'Highland Avenue',\n",
      " 'Bluebird Lane',\n",
      " 'Shirley Street',\n",
      " 'Horseneck Road',\n",
      " 'Pine Hill Road',\n",
      " 'Great Neck Road',\n",
      " 'Pine Hill Road',\n",
      " 'Old County Road',\n",
      " 'American Legion Highway',\n",
      " 'State Road',\n",
      " 'Drift Road',\n",
      " 'Old County Road',\n",
      " 'Riverview Drive',\n",
      " 'Monroe Street',\n",
      " 'Cadmans Neck Road',\n",
      " 'Donovans Lane',\n",
      " 'Fallon Drive',\n",
      " 'Drift Road',\n",
      " 'Washington Street',\n",
      " 'Drift Road',\n",
      " 'East Shore Road',\n",
      " 'Tyler Street',\n",
      " 'Masquesatch Road',\n",
      " 'Drift Road',\n",
      " 'Drift Road',\n",
      " 'Deacon Road',\n",
      " 'Bridge Road',\n",
      " 'Main Road',\n",
      " 'Nicks Way',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Lenox Avenue',\n",
      " 'Willow Way',\n",
      " 'Main Road',\n",
      " 'Majocka Drive',\n",
      " 'State Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Chestnut Hill Drive',\n",
      " 'Melissa Beth Way',\n",
      " 'Drift Road',\n",
      " 'Main Road',\n",
      " 'State Road',\n",
      " 'Main Road',\n",
      " 'Drift Road',\n",
      " 'Almada Street',\n",
      " 'Drift Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Mouse Mill Road',\n",
      " 'East Briggs Road',\n",
      " 'Gifford Road',\n",
      " 'Main Road',\n",
      " 'Old County Road',\n",
      " 'Gifford Road',\n",
      " 'Charlotte White Road Extension',\n",
      " 'Holly Lane',\n",
      " 'Pratt Avenue',\n",
      " 'Main Road',\n",
      " 'Brookwood Drive',\n",
      " 'Morning Dove Drive',\n",
      " 'Main Road',\n",
      " 'Cornell Road',\n",
      " 'Village Way',\n",
      " 'Briggs Road',\n",
      " 'Acoaxet Road',\n",
      " 'Main Road',\n",
      " 'Judges Way',\n",
      " 'Raymond Street',\n",
      " 'River Road',\n",
      " 'Meadowbrook Lane',\n",
      " 'Shannon Drive',\n",
      " 'J Drive',\n",
      " 'R Drive',\n",
      " 'Old Farm Road',\n",
      " 'Sanford Road',\n",
      " 'Sanford Road',\n",
      " 'D Drive',\n",
      " 'N Drive',\n",
      " 'Sanford Road',\n",
      " 'Jordans Way',\n",
      " 'Peckham Lane',\n",
      " 'Holly Trail',\n",
      " 'Sanford Road',\n",
      " 'Howland Road',\n",
      " 'East Morency Avenue',\n",
      " 'Orlando Avenue',\n",
      " 'Angel Court',\n",
      " 'Briggs Road',\n",
      " 'Greenfield Road',\n",
      " 'Meadow Road',\n",
      " 'Adamsville Road',\n",
      " 'River Road',\n",
      " 'River Road',\n",
      " 'Goodwater Street',\n",
      " 'American Legion Highway',\n",
      " 'West Normandin Street',\n",
      " 'Benoit Street',\n",
      " 'Lighthouse Lane',\n",
      " 'Benoit Street',\n",
      " 'Red Tail Lane',\n",
      " 'Tupelo Road',\n",
      " 'Chabot Street',\n",
      " 'River Road',\n",
      " 'Devol Pond Drive',\n",
      " 'Tickle Road',\n",
      " 'Chabot Street',\n",
      " 'Amory Pettey Way',\n",
      " 'Tickle Road',\n",
      " 'Sawdy Drive',\n",
      " 'Tickle Road',\n",
      " 'Tickle Road',\n",
      " 'Beechwood Drive',\n",
      " 'Robert Street',\n",
      " 'Robert Street',\n",
      " 'Robert Street',\n",
      " 'State Road',\n",
      " 'Digger Drive',\n",
      " 'Old Westport Road',\n",
      " 'Kyle Jacob Road',\n",
      " 'Devol Avenue',\n",
      " 'Stella Lane',\n",
      " 'Adamsville Road',\n",
      " 'Windsor Drive',\n",
      " 'Drift Road']\n"
     ]
    }
   ],
   "source": [
    "#Finding values(tag attrib['v]) for unique k (tag attrib['k]) and making observation about the data\n",
    "\n",
    "def values_for_unique_keys(filename):\n",
    "\n",
    "        '''\n",
    "        # Manually provide the item_name value from the list of distinct_keys to calculate \n",
    "        # the values for the corresponding unique key value. We would initialize the key \n",
    "        # variable with one value at a time and without iterating so that we could have an idea\n",
    "        # of what sort of values are there for corresponding key value. Also, we would not iterate\n",
    "        # as it would a long amount of time to calculate the values for all the corresponding unique\n",
    "        # key value\n",
    "        '''\n",
    "        \n",
    "        key='addr:street'\n",
    "        values=[]\n",
    "        EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "        for element in EL:\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k']==key:\n",
    "                    values.append(tag.attrib['v'])\n",
    "            element.clear()\n",
    "        print(key)\n",
    "        pprint.pprint(values)\n",
    "\n",
    "values_for_unique_keys(SAMPLE_FILE)  # Using Sample file as input to audit the addr:street key\n",
    "#values_for_unique_keys(OSM_FILE)   # I could not find any errors with the sample so I looked at the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    }
   ],
   "source": [
    "# How many unique users?\n",
    "\n",
    "def get_user(element):\n",
    "    return element.get('user')\n",
    "\n",
    "\n",
    "def process_users_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get('user'):\n",
    "            users.add(get_user(element))\n",
    "        element.clear()    \n",
    "    return users\n",
    "\n",
    "\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    users = process_users_map(OSM_FILE)\n",
    "\n",
    "print(len(users))\n",
    "# pprint.pprint(users)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6': {'Route 6'},\n",
      " 'Acres': {'Hillcrest Acres'},\n",
      " 'Circle': {'Brushwood Circle',\n",
      "            'Captains Circle',\n",
      "            'Christopher Circle',\n",
      "            'Least Tern Circle'},\n",
      " 'East': {'Horseneck Road East'},\n",
      " 'Extension': {'Charlotte White Road Extension'},\n",
      " 'Highway': {'American Legion Highway'},\n",
      " 'Mall': {'North Dartmouth Mall'},\n",
      " 'Path': {'Swan Pond Path', 'Hobbitt Hill Path', 'Woodcart Path'},\n",
      " 'Pond': {'Allens Pond'},\n",
      " 'Ridge': {'Hawks Nest Ridge'},\n",
      " 'Row': {'Boathouse Row'},\n",
      " 'Run': {'White Oak Run', 'Blue Heron Run', 'Bent Oak Run'},\n",
      " 'Way': {'Abner Potters Way',\n",
      "         'Aimes Way',\n",
      "         'Amory Pettey Way',\n",
      "         'Attatash Way',\n",
      "         'Brayton Way',\n",
      "         'Bridle Way',\n",
      "         'Brothers Way',\n",
      "         'Carters Way',\n",
      "         'Cedar Dell Way',\n",
      "         \"Cheryl's Way\",\n",
      "         'Clydes Way',\n",
      "         'Elihu Way',\n",
      "         'Elise Michelle Way',\n",
      "         'Fisher Pines Way',\n",
      "         'Flores Way',\n",
      "         'Gels Way',\n",
      "         'Grand Pine Way',\n",
      "         'Hebert Way',\n",
      "         'Hersheys Way',\n",
      "         'Hunters Way',\n",
      "         'Indian Spring Way',\n",
      "         'Jennings Way',\n",
      "         'Jillian Way',\n",
      "         'Jordans Way',\n",
      "         'Judges Way',\n",
      "         'Julius Way',\n",
      "         'Kelseys Way',\n",
      "         'Little Pine Way',\n",
      "         'Loretta Way',\n",
      "         'Maya Way',\n",
      "         'Melissa Beth Way',\n",
      "         'Nicks Way',\n",
      "         'Oakstone Way',\n",
      "         'Olin Howland Way',\n",
      "         'Owls Way',\n",
      "         'Pine Cone Way',\n",
      "         'Pine Needle Way',\n",
      "         'Princess Pine Way',\n",
      "         'Rileys Way',\n",
      "         'Roller Coaster Way',\n",
      "         'Sams Way',\n",
      "         'Scotts Way',\n",
      "         'Smiths Way',\n",
      "         'Soules Way',\n",
      "         'Spinnaker Way',\n",
      "         'Stonehaven Way',\n",
      "         'Swartzs Way',\n",
      "         'Thistle Dew Way',\n",
      "         'Tootell Way',\n",
      "         'Village Way',\n",
      "         'Walters Way',\n",
      "         'Wen-Eds Way',\n",
      "         'Whalers Way',\n",
      "         'Wildberry Way',\n",
      "         'Willow Way',\n",
      "         'Windward Way'},\n",
      " 'West': {'Ridgeline Drive West', 'Gulf Road West'}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"WPM.osm\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\",\n",
    "            \"Trail\", \"Parkway\", \"Plaza\", \"Park\"]\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def print_sorted_dic(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print(\"%s: %d\" % (k, v))\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit():\n",
    "\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    pprint.pprint(dict(street_types))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridgeline Drive West => Ridgeline Drive West\n",
      "Gulf Road West => Gulf Road West\n",
      "North Dartmouth Mall => North Dartmouth Mall\n",
      "Aimes Way => Aimes Way\n",
      "Carters Way => Carters Way\n",
      "Nicks Way => Nicks Way\n",
      "Gels Way => Gels Way\n",
      "Cheryl's Way => Cheryl's Way\n",
      "Princess Pine Way => Princess Pine Way\n",
      "Soules Way => Soules Way\n",
      "Pine Cone Way => Pine Cone Way\n",
      "Thistle Dew Way => Thistle Dew Way\n",
      "Hebert Way => Hebert Way\n",
      "Amory Pettey Way => Amory Pettey Way\n",
      "Roller Coaster Way => Roller Coaster Way\n",
      "Maya Way => Maya Way\n",
      "Elihu Way => Elihu Way\n",
      "Spinnaker Way => Spinnaker Way\n",
      "Olin Howland Way => Olin Howland Way\n",
      "Sams Way => Sams Way\n",
      "Brothers Way => Brothers Way\n",
      "Oakstone Way => Oakstone Way\n",
      "Wen-Eds Way => Wen-Eds Way\n",
      "Hersheys Way => Hersheys Way\n",
      "Jordans Way => Jordans Way\n",
      "Tootell Way => Tootell Way\n",
      "Cedar Dell Way => Cedar Dell Way\n",
      "Owls Way => Owls Way\n",
      "Wildberry Way => Wildberry Way\n",
      "Village Way => Village Way\n",
      "Rileys Way => Rileys Way\n",
      "Abner Potters Way => Abner Potters Way\n",
      "Clydes Way => Clydes Way\n",
      "Kelseys Way => Kelseys Way\n",
      "Whalers Way => Whalers Way\n",
      "Grand Pine Way => Grand Pine Way\n",
      "Jillian Way => Jillian Way\n",
      "Loretta Way => Loretta Way\n",
      "Indian Spring Way => Indian Spring Way\n",
      "Stonehaven Way => Stonehaven Street\n",
      "Melissa Beth Way => Melissa Beth Way\n",
      "Jennings Way => Jennings Way\n",
      "Judges Way => Judges Way\n",
      "Swartzs Way => Swartzs Way\n",
      "Scotts Way => Scotts Way\n",
      "Pine Needle Way => Pine Needle Way\n",
      "Willow Way => Willow Way\n",
      "Fisher Pines Way => Fisher Pines Way\n",
      "Attatash Way => Attatash Way\n",
      "Brayton Way => Brayton Way\n",
      "Bridle Way => Bridle Way\n",
      "Flores Way => Flores Way\n",
      "Windward Way => Windward Way\n",
      "Elise Michelle Way => Elise Michelle Way\n",
      "Hunters Way => Hunters Way\n",
      "Walters Way => Walters Way\n",
      "Smiths Way => Smiths Way\n",
      "Julius Way => Julius Way\n",
      "Little Pine Way => Little Pine Way\n",
      "Allens Pond => Allens Pond\n",
      "Swan Pond Path => Swan Pond Path\n",
      "Hobbitt Hill Path => Hobbitt Hill Path\n",
      "Woodcart Path => Woodcart Path\n",
      "White Oak Run => White Oak Run\n",
      "Blue Heron Run => Blue Heron Run\n",
      "Bent Oak Run => Bent Oak Run\n",
      "Christopher Circle => Christopher Circle\n",
      "Brushwood Circle => Brushwood Circle\n",
      "Least Tern Circle => Least Tern Circle\n",
      "Captains Circle => Captains Circle\n",
      "Horseneck Road East => Horseneck Road East\n",
      "American Legion Highway => American Legion Highway\n",
      "Hillcrest Acres => Hillcrest Acres\n",
      "Charlotte White Road Extension => Charlotte White Road Extension\n",
      "Boathouse Row => Boathouse Row\n",
      "Hawks Nest Ridge => Hawks Nest Ridge\n"
     ]
    }
   ],
   "source": [
    "mapping = {\"St\": \"Street\",\n",
    "           \"ST\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"St,\": \"Street\",\n",
    "           \"Street.\": \"Street\",\n",
    "           \"street\": \"Street\",\n",
    "           \"Sq\": \"Square\",\n",
    "           \"Rd.\": \"Road\",\n",
    "           \"Rd\": \"Road\",\n",
    "           \"Ave\": \"Avenue\",\n",
    "           \"DR.\": \"Drive\"\n",
    "           }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for key, value in mapping.items():\n",
    "        if re.search(key, name):\n",
    "            name = re.sub(street_type_re, value, name)\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print (name, \"=>\", better_name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_schema.py\n",
    "\n",
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaped and exported.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "from my_schema import SCHEMA\n",
    "\n",
    "OSM_PATH = \"WPM.osm\"\n",
    "file_in = open(\"WPM.osm\")\n",
    "root = ET.parse(\"WPM.osm\").getroot()\n",
    "#schema_file = open(\"my_schema.py\")\n",
    "\n",
    "def find_element():\n",
    "    element = []\n",
    "    for item in root.find(\"node\"):\n",
    "        element = ET.dump(item)\n",
    "        return element\n",
    "    \n",
    "element = find_element\n",
    "    \n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.SCHEMA\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "  \n",
    "    if element.tag == 'node':\n",
    "\n",
    "            for node_field in node_attr_fields:\n",
    "                node_attribs[node_field] = element.attrib[node_field]\n",
    "\n",
    "            for tag in element.iter('tag'):\n",
    "                k = tag.attrib['k']\n",
    "\n",
    "                # ignores tags containing problem characters in the k tag attribute:\n",
    "\n",
    "                if re.search(PROBLEMCHARS,k):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                tag_dict = {}\n",
    "\n",
    "                tag_dict['id'] = node_attribs['id']\n",
    "\n",
    "                colon_find = re.split('[:]', k)\n",
    "\n",
    "                if len(colon_find) == 1:\n",
    "\n",
    "                    tag_dict['key'] = k\n",
    "                    tag_dict['type'] = 'regular'\n",
    "\n",
    "                elif len(colon_find) == 2:\n",
    "\n",
    "                    tag_dict['key'] = colon_find[1]\n",
    "                    tag_dict['type'] = colon_find[0]\n",
    "\n",
    "                elif len(colon_find) > 2:\n",
    "\n",
    "                    tag_dict['key'] = ':'.join(colon_find[1:])\n",
    "                    tag_dict['type'] = colon_find[0]\n",
    "\n",
    "                tag_dict['value'] = tag.attrib['v']\n",
    "\n",
    "                tags.append(tag_dict)\n",
    "\n",
    "            return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    elif element.tag == 'way':\n",
    "\n",
    "        for way_field in way_attr_fields:\n",
    "            way_attribs[way_field] =element.attrib[way_field]\n",
    "\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.attrib['k']\n",
    "\n",
    "            # ignores tags containing problem characters in the k tag attribute:\n",
    "\n",
    "            if re.search(PROBLEMCHARS,k):\n",
    "                print (\"Problem character found - skipping element\")\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tag_dict = {}\n",
    "\n",
    "            tag_dict['id'] = way_attribs['id']\n",
    "\n",
    "            colon_find = re.split('[:]', k)\n",
    "\n",
    "            if len(colon_find) == 1:\n",
    "\n",
    "                tag_dict['key'] = k\n",
    "                tag_dict['type'] = 'regular'\n",
    "\n",
    "            elif len(colon_find) == 2:\n",
    "\n",
    "                tag_dict['key'] = colon_find[1]\n",
    "                tag_dict['type'] = colon_find[0]\n",
    "\n",
    "            elif len(colon_find) > 2:\n",
    "\n",
    "                tag_dict['key'] = ':'.join(colon_find[1:])\n",
    "                tag_dict['type'] = colon_find[0]\n",
    "\n",
    "            tag_dict['value'] = tag.attrib['v']\n",
    "\n",
    "            tags.append(tag_dict)\n",
    "\n",
    "        n = 0\n",
    "        for nd in element.iter('nd'):\n",
    "\n",
    "            nd_dict = {}\n",
    "\n",
    "            nd_dict['id'] = way_attribs['id']\n",
    "            nd_dict['node_id'] = nd.attrib['ref']\n",
    "            nd_dict['position'] = n\n",
    "            way_nodes.append(nd_dict)\n",
    "            n+=1\n",
    "\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: v for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w', \"utf-8\") as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w', \"utf-8\") as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w', \"utf-8\") as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w', \"utf-8\") as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w', \"utf-8\") as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n",
    "    \n",
    "print(\"Reshaped and exported.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened database successfully\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\"\"\"import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\"\"\"\n",
    "conn = sqlite3.connect('WPM.db')\n",
    "cursor = conn.cursor()\n",
    "print(\"Opened database successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self note - Do not need to re-create them every time.\n",
    "\n",
    "#https://www.sqlitetutorial.net/sqlite-python/create-tables/\n",
    "\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "\n",
    "def create_table(conn, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param conn: Connection object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c = conn.cursor()\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def main():\n",
    "    database = r\"C:\\Users\\wille\\WPM.db\"\n",
    "\n",
    "    sql_create_nodes_table = \"\"\" CREATE TABLE IF NOT EXISTS nodes (\n",
    "        id INTEGER PRIMARY KEY NOT NULL,\n",
    "        lat FLOAT,\n",
    "        lon FLOAT,\n",
    "        user TEXT,\n",
    "        uid INTEGER,\n",
    "        version TEXT,\n",
    "        changeset INTEGER,\n",
    "        timestamp TEXT\n",
    "    );\"\"\"\n",
    "\n",
    "    sql_create_nodes_tags_table = \"\"\"CREATE TABLE IF NOT EXISTS nodes_tags (\n",
    "        id INTEGER,\n",
    "        key TEXT,\n",
    "        value TEXT,\n",
    "        type TEXT,\n",
    "        FOREIGN KEY (id) REFERENCES nodes(id)\n",
    "    );\"\"\"\n",
    "\n",
    "\n",
    "    sql_create_ways_table = \"\"\"CREATE TABLE IF NOT EXISTS ways (\n",
    "         id INTEGER PRIMARY KEY NOT NULL,\n",
    "         user TEXT,\n",
    "         uid INTEGER,\n",
    "         version TEXT,\n",
    "         changeset INTEGER,\n",
    "         timestamp TEXT\n",
    "     );\"\"\"\n",
    "\n",
    "    sql_create_ways_tags_table = \"\"\"CREATE TABLE IF NOT EXISTS ways_tags (\n",
    "         id INTEGER NOT NULL,\n",
    "         key TEXT NOT NULL,\n",
    "         value TEXT NOT NULL,\n",
    "         type TEXT,\n",
    "         FOREIGN KEY (id) REFERENCES ways(id)\n",
    "     );\"\"\"\n",
    "\n",
    "    sql_create_ways_nodes_table = \"\"\"CREATE TABLE IF NOT EXISTS ways_nodes (\n",
    "         id INTEGER NOT NULL,\n",
    "         node_id INTEGER NOT NULL,\n",
    "         position INTEGER NOT NULL,\n",
    "         FOREIGN KEY (id) REFERENCES ways(id),\n",
    "         FOREIGN KEY (node_id) REFERENCES nodes(id)\n",
    "     );\"\"\"\n",
    "\n",
    "\n",
    "    # create a database connection\n",
    "    conn = create_connection(database)\n",
    "\n",
    "     # create tables\n",
    "    if conn is not None:\n",
    "         # create nodes table\n",
    "        create_table(conn, sql_create_nodes_table)\n",
    "\n",
    "         # create nodes tags table\n",
    "        create_table(conn, sql_create_nodes_tags_table)\n",
    "        \n",
    "         # create ways table\n",
    "        create_table(conn, sql_create_ways_table)\n",
    "\n",
    "         # create ways tags table\n",
    "        create_table(conn, sql_create_ways_tags_table)\n",
    "\n",
    "         # create ways nodes table\n",
    "        create_table(conn, sql_create_ways_nodes_table)\n",
    "       \n",
    "    else:\n",
    "        print(\"Error! cannot create the database connection.\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

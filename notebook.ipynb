{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pprint\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "OSM_FILE = \"WPM\"  \n",
    "SAMPLE_FILE = \"sample_WPM.osm\"\n",
    "\n",
    "# Parameter: take every k-th top level element\n",
    "k = 42\n",
    "\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\n",
    "    Reference:\n",
    "    http://stackoverflow.com/questions/3095434/inserting-newlines-in-xml-file-generated-via-xml-etree-elementtree-in-python\n",
    "    \"\"\"\n",
    "    context = iter(ET.iterparse(osm_file, events=('start', 'end')))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "with open(SAMPLE_FILE, 'wb') as output:\n",
    "    output.write(b'<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "    output.write(b'<osm>\\n  ')\n",
    "\n",
    "    # Write every kth top level element\n",
    "    for i, element in enumerate(get_element(OSM_FILE)):\n",
    "        if i % k == 0:\n",
    "            output.write(ET.tostring(element, encoding='utf-8'))\n",
    "\n",
    "    output.write(b'</osm>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'member': 33,\n",
      " 'nd': 10707,\n",
      " 'node': 9373,\n",
      " 'osm': 1,\n",
      " 'relation': 4,\n",
      " 'tag': 3130,\n",
      " 'way': 632}\n"
     ]
    }
   ],
   "source": [
    "# Finding out what tags there are and how many of each\n",
    "\n",
    "\n",
    "def count_tags(filename):\n",
    "    tags = {}\n",
    "    for event, elem in ET.iterparse(filename, events=('start', )):\n",
    "        if elem.tag not in tags:\n",
    "            tags[elem.tag] = 1\n",
    "        else:\n",
    "            tags[elem.tag] += 1\n",
    "    return tags\n",
    "\n",
    "def test():\n",
    "\n",
    "    tags = count_tags('sample_WPM.osm')\n",
    "    pprint.pprint(tags)\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lower': 84411, 'lower_colon': 20640, 'other': 25527, 'problemchars': 0}\n"
     ]
    }
   ],
   "source": [
    "# Checking \"k\" value for each tag and looking for potential problems\n",
    "\n",
    "# 3 regular expressions I used to check for patterns in tags\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "# Checking for problematic characters\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "\n",
    "# Changing the data model into a dictionary\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        if lower.search(element.attrib['k']):\n",
    "            keys['lower'] += 1\n",
    "        elif lower_colon.search(element.attrib['k']):\n",
    "            keys['lower_colon'] += 1\n",
    "        elif problemchars.search(element.attrib['k']):\n",
    "            keys['problemchars'] = keys['problemchars'] + 1\n",
    "        else:    \n",
    "            keys['other'] += 1  \n",
    "#           print element.attrib['k']\n",
    "    return keys\n",
    "\n",
    "\n",
    "def process_keys_map(filename):\n",
    "    keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "    return keys\n",
    "\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    keys = process_keys_map(OSM_FILE)\n",
    "    pprint.pprint(keys)\n",
    "f.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of unique keys (tag attrib['k'])is 257\n",
      "['access',\n",
      " 'addr:city',\n",
      " 'addr:country',\n",
      " 'addr:housenumber',\n",
      " 'addr:postcode',\n",
      " 'addr:state',\n",
      " 'addr:street',\n",
      " 'addr:unit',\n",
      " 'admin_level',\n",
      " 'aeroway',\n",
      " 'agricultural',\n",
      " 'alt_name',\n",
      " 'amenity',\n",
      " 'area',\n",
      " 'atm',\n",
      " 'attribution',\n",
      " 'barrier',\n",
      " 'bench',\n",
      " 'bicycle',\n",
      " 'boundary',\n",
      " 'boundary_type',\n",
      " 'brand',\n",
      " 'brand:wikidata',\n",
      " 'brand:wikipedia',\n",
      " 'bridge',\n",
      " 'building',\n",
      " 'building:levels',\n",
      " 'cables',\n",
      " 'capacity',\n",
      " 'changing_table',\n",
      " 'changing_table:location',\n",
      " 'circuits',\n",
      " 'clothes',\n",
      " 'colour',\n",
      " 'condition',\n",
      " 'contact:email',\n",
      " 'contact:website',\n",
      " 'covered',\n",
      " 'craft',\n",
      " 'created_by',\n",
      " 'cuisine',\n",
      " 'cycleway:both',\n",
      " 'cycleway:right',\n",
      " 'destination',\n",
      " 'destination:ref',\n",
      " 'destination:street',\n",
      " 'dispensing',\n",
      " 'ele',\n",
      " 'emergency',\n",
      " 'entrance',\n",
      " 'expressway',\n",
      " 'faa',\n",
      " 'fee',\n",
      " 'fire_hydrant:position',\n",
      " 'fire_hydrant:type',\n",
      " 'foot',\n",
      " 'frequency',\n",
      " 'generator:method',\n",
      " 'generator:source',\n",
      " 'gnis:Class',\n",
      " 'gnis:County',\n",
      " 'gnis:County_num',\n",
      " 'gnis:ST_alpha',\n",
      " 'gnis:ST_num',\n",
      " 'gnis:county_id',\n",
      " 'gnis:county_name',\n",
      " 'gnis:created',\n",
      " 'gnis:feature_id',\n",
      " 'gnis:feature_type',\n",
      " 'gnis:id',\n",
      " 'gnis:import_uuid',\n",
      " 'gnis:reviewed',\n",
      " 'gnis:state_id',\n",
      " 'golf',\n",
      " 'grades',\n",
      " 'handicap',\n",
      " 'healthcare',\n",
      " 'hgv',\n",
      " 'highway',\n",
      " 'historic',\n",
      " 'historical',\n",
      " 'horse',\n",
      " 'import_uuid',\n",
      " 'incline',\n",
      " 'indoor',\n",
      " 'intermittent',\n",
      " 'internet_access',\n",
      " 'internet_access:fee',\n",
      " 'is_in',\n",
      " 'junction:ref',\n",
      " 'jurisdiction',\n",
      " 'landuse',\n",
      " 'lanes',\n",
      " 'layer',\n",
      " 'leaf_type',\n",
      " 'leisure',\n",
      " 'length',\n",
      " 'level',\n",
      " 'lit',\n",
      " 'location',\n",
      " 'man_made',\n",
      " 'maritime',\n",
      " 'massgis:ALT_SITE_N',\n",
      " 'massgis:ARTICLE97',\n",
      " 'massgis:ASSESS_ACR',\n",
      " 'massgis:ASSESS_BLK',\n",
      " 'massgis:ASSESS_LOT',\n",
      " 'massgis:ASSESS_MAP',\n",
      " 'massgis:ASSESS_SUB',\n",
      " 'massgis:ATT_DATE',\n",
      " 'massgis:BASE_MAP',\n",
      " 'massgis:BOND_ACCT',\n",
      " 'massgis:CAL_DATE_R',\n",
      " 'massgis:COMMENTS',\n",
      " 'massgis:DCAM_ID',\n",
      " 'massgis:DEED_ACRES',\n",
      " 'massgis:EOEAINVOLV',\n",
      " 'massgis:FEESYM',\n",
      " 'massgis:FEE_OWNER',\n",
      " 'massgis:FY_FUNDING',\n",
      " 'massgis:GRANTPROG1',\n",
      " 'massgis:GRANTTYPE1',\n",
      " 'massgis:INTSYM',\n",
      " 'massgis:IT_VALC',\n",
      " 'massgis:IT_VALDESC',\n",
      " 'massgis:LEV_PROT',\n",
      " 'massgis:LOC_ID',\n",
      " 'massgis:MANAGER',\n",
      " 'massgis:MANAGR_ABR',\n",
      " 'massgis:MANAGR_TYP',\n",
      " 'massgis:OBJECTID',\n",
      " 'massgis:OLI_1_ABRV',\n",
      " 'massgis:OLI_1_INT',\n",
      " 'massgis:OLI_1_ORG',\n",
      " 'massgis:OLI_1_TYPE',\n",
      " 'massgis:OLI_2_ABRV',\n",
      " 'massgis:OLI_2_INT',\n",
      " 'massgis:OLI_2_ORG',\n",
      " 'massgis:OLI_2_TYPE',\n",
      " 'massgis:OS_DEED_BO',\n",
      " 'massgis:OS_DEED_PA',\n",
      " 'massgis:OS_ID',\n",
      " 'massgis:OWNER_ABRV',\n",
      " 'massgis:OWNER_TYPE',\n",
      " 'massgis:PALIS_ID',\n",
      " 'massgis:POLY_CODE',\n",
      " 'massgis:POLY_ID',\n",
      " 'massgis:PRIM_PURP',\n",
      " 'massgis:PROJ_ID1',\n",
      " 'massgis:PROJ_ID2',\n",
      " 'massgis:PUB_ACCESS',\n",
      " 'massgis:SITE_NAME',\n",
      " 'massgis:SOURCE',\n",
      " 'massgis:SOURCE_MAP',\n",
      " 'massgis:SOURCE_SCA',\n",
      " 'massgis:SOURCE_TYP',\n",
      " 'massgis:TOWN_ID',\n",
      " 'massgis:WETCODE',\n",
      " 'massgis:school_id',\n",
      " 'massgis:way_id',\n",
      " 'material',\n",
      " 'maxspeed',\n",
      " 'maxspeed:advisory',\n",
      " 'motor_vehicle',\n",
      " 'name',\n",
      " 'name:en',\n",
      " 'natural',\n",
      " 'noexit',\n",
      " 'noref',\n",
      " 'note',\n",
      " 'office',\n",
      " 'official_name',\n",
      " 'old_name',\n",
      " 'oneway',\n",
      " 'opening_hours',\n",
      " 'opening_hours:covid19',\n",
      " 'operator',\n",
      " 'orig_name',\n",
      " 'owner',\n",
      " 'ownership',\n",
      " 'par',\n",
      " 'park_ride',\n",
      " 'parking',\n",
      " 'payment',\n",
      " 'phone',\n",
      " 'place',\n",
      " 'plant:method',\n",
      " 'plant:output:electricity',\n",
      " 'plant:source',\n",
      " 'playground',\n",
      " 'population',\n",
      " 'power',\n",
      " 'product',\n",
      " 'protect_class',\n",
      " 'protected',\n",
      " 'protection_title',\n",
      " 'public_transport',\n",
      " 'railway',\n",
      " 'ramp',\n",
      " 'ref',\n",
      " 'ref:nrhp',\n",
      " 'ref:walmart',\n",
      " 'region',\n",
      " 'religion',\n",
      " 'roof:levels',\n",
      " 'roof:shape',\n",
      " 'sac_scale',\n",
      " 'sand',\n",
      " 'screen',\n",
      " 'service',\n",
      " 'shelter',\n",
      " 'shop',\n",
      " 'sidewalk',\n",
      " 'smoking',\n",
      " 'source',\n",
      " 'source:hgv',\n",
      " 'source:maxspeed',\n",
      " 'source:name',\n",
      " 'source:url',\n",
      " 'source_url',\n",
      " 'sport',\n",
      " 'start_date',\n",
      " 'substance',\n",
      " 'substation',\n",
      " 'supervised',\n",
      " 'surface',\n",
      " 'takeaway',\n",
      " 'tidal',\n",
      " 'tiger:cfcc',\n",
      " 'tiger:name_base',\n",
      " 'tiger:name_base_1',\n",
      " 'tiger:name_direction_prefix',\n",
      " 'tiger:name_direction_suffix',\n",
      " 'tiger:name_type',\n",
      " 'tiger:name_type_1',\n",
      " 'tiger:reviewed',\n",
      " 'toilets',\n",
      " 'tourism',\n",
      " 'tower:type',\n",
      " 'traffic_calming',\n",
      " 'traffic_sign',\n",
      " 'traffic_signals',\n",
      " 'traffic_signals:direction',\n",
      " 'tunnel',\n",
      " 'turn:lanes',\n",
      " 'type',\n",
      " 'voltage',\n",
      " 'wall',\n",
      " 'water',\n",
      " 'waterway',\n",
      " 'website',\n",
      " 'wetland',\n",
      " 'wheelchair',\n",
      " 'width',\n",
      " 'wikidata',\n",
      " 'wikipedia']\n"
     ]
    }
   ],
   "source": [
    "# Finding unique k (tag attrib['k']) and count\n",
    "\n",
    "def unique_keys(filename):\n",
    "    distinct_keys=[]\n",
    "    count=1\n",
    "\n",
    "    EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "    for element in EL:\n",
    "        if element.tag=='node' or element.tag=='way':\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k'] not in distinct_keys:\n",
    "                    distinct_keys.append(tag.attrib['k'])\n",
    "                    count+=1\n",
    "    distinct_keys.sort()\n",
    "    print(\"Total number of unique keys (tag attrib['k'])is {}\".format(count))\n",
    "    \n",
    "#    return distinct_keys\n",
    "      \n",
    "    pprint.pprint(distinct_keys) # looks cleaner this way\n",
    "    \n",
    "                \n",
    "#unique_keys(SAMPLE_FILE)  # Using Sample file as input to audit the addr:street key\n",
    "unique_keys(OSM_FILE)  \n",
    "#I used the sample file first and I became more curious and took a look at the whole file since it was not that big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addr:street\n",
      "['State Road',\n",
      " 'Potomska Road',\n",
      " 'Faunce Corner Mall Road',\n",
      " 'Rock Odundee Road',\n",
      " 'Faunce Corner Road',\n",
      " 'Shaker Road',\n",
      " 'Howland Mill Lane',\n",
      " 'South Brown Street',\n",
      " 'Hixville Road',\n",
      " 'Bellevue Street',\n",
      " 'Green Drive',\n",
      " 'Emmett Avenue',\n",
      " 'Cross Road',\n",
      " 'Elliot Street',\n",
      " 'Rockville Avenue',\n",
      " 'Gaffney Road',\n",
      " 'Greystone Avenue',\n",
      " 'Gaffney Road',\n",
      " 'Cedar Avenue',\n",
      " 'Juliette Street',\n",
      " 'State Road',\n",
      " 'State Road',\n",
      " 'Old Westport Road',\n",
      " 'Chase Road',\n",
      " 'Longmeadow Road',\n",
      " 'Chase Road',\n",
      " 'Barneys Joy Road',\n",
      " 'Azalea Drive',\n",
      " 'Cross Road',\n",
      " 'State Road',\n",
      " 'Duane Avenue',\n",
      " 'Yorke Street',\n",
      " 'Horseneck Road',\n",
      " 'Morton Avenue',\n",
      " 'Yorke Street',\n",
      " 'Hancock Street',\n",
      " 'Fisher Road',\n",
      " 'Woodcock Road',\n",
      " 'Woodcock Road',\n",
      " 'Elswick Street',\n",
      " 'Hillcrest Street',\n",
      " 'Lucy Little Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Slades Corner Road',\n",
      " 'Horseneck Road',\n",
      " 'Slades Farm Lane',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Christine Drive',\n",
      " 'Fisher Road',\n",
      " 'Eliza Lane',\n",
      " 'Red Oak Lane',\n",
      " 'Fisher Road',\n",
      " 'Fisher Pines Way',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Red Oak Lane',\n",
      " 'Division Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Reed Road',\n",
      " 'State Road',\n",
      " 'Sherbrooke Road',\n",
      " 'Sherbrooke Road',\n",
      " 'Lakewood Road',\n",
      " 'Lake Avenue',\n",
      " 'Line Road',\n",
      " 'East King Road',\n",
      " 'Division Road',\n",
      " 'Division Road',\n",
      " 'Horseneck Road',\n",
      " 'Fisher Road',\n",
      " 'Fisher Road',\n",
      " 'Autumn Drive',\n",
      " 'Beeden Road',\n",
      " 'Autumn Drive',\n",
      " 'Horseneck Road',\n",
      " 'Pettey Lane',\n",
      " 'Miss Rachel Trail',\n",
      " 'Old County Road',\n",
      " 'American Legion Highway',\n",
      " 'Reed Road',\n",
      " 'Lincoln Avenue',\n",
      " 'Reed Road',\n",
      " 'Reed Road',\n",
      " 'Highridge Road',\n",
      " 'Pine Hill Road',\n",
      " 'Shady Lane',\n",
      " 'Highland Avenue',\n",
      " 'Cummings Lane',\n",
      " 'Westlook Lane',\n",
      " 'Highland Avenue',\n",
      " 'Bluebird Lane',\n",
      " 'Shirley Street',\n",
      " 'Horseneck Road',\n",
      " 'Pine Hill Road',\n",
      " 'Great Neck Road',\n",
      " 'Pine Hill Road',\n",
      " 'Old County Road',\n",
      " 'American Legion Highway',\n",
      " 'State Road',\n",
      " 'Drift Road',\n",
      " 'Old County Road',\n",
      " 'Riverview Drive',\n",
      " 'Monroe Street',\n",
      " 'Cadmans Neck Road',\n",
      " 'Donovans Lane',\n",
      " 'Fallon Drive',\n",
      " 'Drift Road',\n",
      " 'Washington Street',\n",
      " 'Drift Road',\n",
      " 'East Shore Road',\n",
      " 'Tyler Street',\n",
      " 'Masquesatch Road',\n",
      " 'Drift Road',\n",
      " 'Drift Road',\n",
      " 'Deacon Road',\n",
      " 'Bridge Road',\n",
      " 'Main Road',\n",
      " 'Nicks Way',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Lenox Avenue',\n",
      " 'Willow Way',\n",
      " 'Main Road',\n",
      " 'Majocka Drive',\n",
      " 'State Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Chestnut Hill Drive',\n",
      " 'Melissa Beth Way',\n",
      " 'Drift Road',\n",
      " 'Main Road',\n",
      " 'State Road',\n",
      " 'Main Road',\n",
      " 'Drift Road',\n",
      " 'Almada Street',\n",
      " 'Drift Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Main Road',\n",
      " 'Mouse Mill Road',\n",
      " 'East Briggs Road',\n",
      " 'Gifford Road',\n",
      " 'Main Road',\n",
      " 'Old County Road',\n",
      " 'Gifford Road',\n",
      " 'Charlotte White Road Extension',\n",
      " 'Holly Lane',\n",
      " 'Pratt Avenue',\n",
      " 'Main Road',\n",
      " 'Brookwood Drive',\n",
      " 'Morning Dove Drive',\n",
      " 'Main Road',\n",
      " 'Cornell Road',\n",
      " 'Village Way',\n",
      " 'Briggs Road',\n",
      " 'Acoaxet Road',\n",
      " 'Main Road',\n",
      " 'Judges Way',\n",
      " 'Raymond Street',\n",
      " 'River Road',\n",
      " 'Meadowbrook Lane',\n",
      " 'Shannon Drive',\n",
      " 'J Drive',\n",
      " 'R Drive',\n",
      " 'Old Farm Road',\n",
      " 'Sanford Road',\n",
      " 'Sanford Road',\n",
      " 'D Drive',\n",
      " 'N Drive',\n",
      " 'Sanford Road',\n",
      " 'Jordans Way',\n",
      " 'Peckham Lane',\n",
      " 'Holly Trail',\n",
      " 'Sanford Road',\n",
      " 'Howland Road',\n",
      " 'East Morency Avenue',\n",
      " 'Orlando Avenue',\n",
      " 'Angel Court',\n",
      " 'Briggs Road',\n",
      " 'Greenfield Road',\n",
      " 'Meadow Road',\n",
      " 'Adamsville Road',\n",
      " 'River Road',\n",
      " 'River Road',\n",
      " 'Goodwater Street',\n",
      " 'American Legion Highway',\n",
      " 'West Normandin Street',\n",
      " 'Benoit Street',\n",
      " 'Lighthouse Lane',\n",
      " 'Benoit Street',\n",
      " 'Red Tail Lane',\n",
      " 'Tupelo Road',\n",
      " 'Chabot Street',\n",
      " 'River Road',\n",
      " 'Devol Pond Drive',\n",
      " 'Tickle Road',\n",
      " 'Chabot Street',\n",
      " 'Amory Pettey Way',\n",
      " 'Tickle Road',\n",
      " 'Sawdy Drive',\n",
      " 'Tickle Road',\n",
      " 'Tickle Road',\n",
      " 'Beechwood Drive',\n",
      " 'Robert Street',\n",
      " 'Robert Street',\n",
      " 'Robert Street',\n",
      " 'State Road',\n",
      " 'Digger Drive',\n",
      " 'Old Westport Road',\n",
      " 'Kyle Jacob Road',\n",
      " 'Devol Avenue',\n",
      " 'Stella Lane',\n",
      " 'Adamsville Road',\n",
      " 'Windsor Drive',\n",
      " 'Drift Road']\n"
     ]
    }
   ],
   "source": [
    "#Finding values(tag attrib['v]) for unique k (tag attrib['k]) and making observation about the data\n",
    "\n",
    "def values_for_unique_keys(filename):\n",
    "\n",
    "        '''\n",
    "        # Manually provide the item_name value from the list of distinct_keys to calculate \n",
    "        # the values for the corresponding unique key value. We would initialize the key \n",
    "        # variable with one value at a time and without iterating so that we could have an idea\n",
    "        # of what sort of values are there for corresponding key value. Also, we would not iterate\n",
    "        # as it would a long amount of time to calculate the values for all the corresponding unique\n",
    "        # key value\n",
    "        '''\n",
    "        \n",
    "        key='addr:street'\n",
    "        values=[]\n",
    "        EL=get_element(filename, tags=('node', 'way', 'relation'))\n",
    "        for element in EL:\n",
    "            for tag in element.iter('tag'):\n",
    "                if tag.attrib['k']==key:\n",
    "                    values.append(tag.attrib['v'])\n",
    "            element.clear()\n",
    "        print(key)\n",
    "        pprint.pprint(values)\n",
    "\n",
    "values_for_unique_keys(SAMPLE_FILE)  # Using Sample file as input to audit the addr:street key\n",
    "#values_for_unique_keys(OSM_FILE)   # I could not find any errors with the sample so I looked at the whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "457\n"
     ]
    }
   ],
   "source": [
    "# How many unique users?\n",
    "\n",
    "def get_user(element):\n",
    "    return element.get('user')\n",
    "\n",
    "\n",
    "def process_users_map(filename):\n",
    "    users = set()\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        if element.get('user'):\n",
    "            users.add(get_user(element))\n",
    "        element.clear()    \n",
    "    return users\n",
    "\n",
    "\n",
    "with open(OSM_FILE,'rb') as f:\n",
    "    users = process_users_map(OSM_FILE)\n",
    "\n",
    "print(len(users))\n",
    "# pprint.pprint(users)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'6': {'Route 6'},\n",
      " 'Acres': {'Hillcrest Acres'},\n",
      " 'Circle': {'Brushwood Circle',\n",
      "            'Captains Circle',\n",
      "            'Christopher Circle',\n",
      "            'Least Tern Circle'},\n",
      " 'East': {'Horseneck Road East'},\n",
      " 'Extension': {'Charlotte White Road Extension'},\n",
      " 'Highway': {'American Legion Highway'},\n",
      " 'Mall': {'North Dartmouth Mall'},\n",
      " 'Path': {'Hobbitt Hill Path', 'Woodcart Path', 'Swan Pond Path'},\n",
      " 'Pond': {'Allens Pond'},\n",
      " 'Ridge': {'Hawks Nest Ridge'},\n",
      " 'Row': {'Boathouse Row'},\n",
      " 'Run': {'White Oak Run', 'Blue Heron Run', 'Bent Oak Run'},\n",
      " 'Way': {'Abner Potters Way',\n",
      "         'Aimes Way',\n",
      "         'Amory Pettey Way',\n",
      "         'Attatash Way',\n",
      "         'Brayton Way',\n",
      "         'Bridle Way',\n",
      "         'Brothers Way',\n",
      "         'Carters Way',\n",
      "         'Cedar Dell Way',\n",
      "         \"Cheryl's Way\",\n",
      "         'Clydes Way',\n",
      "         'Elihu Way',\n",
      "         'Elise Michelle Way',\n",
      "         'Fisher Pines Way',\n",
      "         'Flores Way',\n",
      "         'Gels Way',\n",
      "         'Grand Pine Way',\n",
      "         'Hebert Way',\n",
      "         'Hersheys Way',\n",
      "         'Hunters Way',\n",
      "         'Indian Spring Way',\n",
      "         'Jennings Way',\n",
      "         'Jillian Way',\n",
      "         'Jordans Way',\n",
      "         'Judges Way',\n",
      "         'Julius Way',\n",
      "         'Kelseys Way',\n",
      "         'Little Pine Way',\n",
      "         'Loretta Way',\n",
      "         'Maya Way',\n",
      "         'Melissa Beth Way',\n",
      "         'Nicks Way',\n",
      "         'Oakstone Way',\n",
      "         'Olin Howland Way',\n",
      "         'Owls Way',\n",
      "         'Pine Cone Way',\n",
      "         'Pine Needle Way',\n",
      "         'Princess Pine Way',\n",
      "         'Rileys Way',\n",
      "         'Roller Coaster Way',\n",
      "         'Sams Way',\n",
      "         'Scotts Way',\n",
      "         'Smiths Way',\n",
      "         'Soules Way',\n",
      "         'Spinnaker Way',\n",
      "         'Stonehaven Way',\n",
      "         'Swartzs Way',\n",
      "         'Thistle Dew Way',\n",
      "         'Tootell Way',\n",
      "         'Village Way',\n",
      "         'Walters Way',\n",
      "         'Wen-Eds Way',\n",
      "         'Whalers Way',\n",
      "         'Wildberry Way',\n",
      "         'Willow Way',\n",
      "         'Windward Way'},\n",
      " 'West': {'Ridgeline Drive West', 'Gulf Road West'}}\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Your task in this exercise has two steps:\n",
    "\n",
    "- audit the OSMFILE and change the variable 'mapping' to reflect the changes needed to fix \n",
    "    the unexpected street types to the appropriate ones in the expected list.\n",
    "    You have to add mappings only for the actual problems you find in this OSMFILE,\n",
    "    not a generalized solution, since that may and will depend on the particular area you are auditing.\n",
    "- write the update_name function, to actually fix the street name.\n",
    "    The function takes a string with street name as an argument and should return the fixed name\n",
    "    We have provided a simple test so that you see what exactly is expected\n",
    "\"\"\"\n",
    "import xml.etree.cElementTree as ET\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "OSMFILE = \"WPM\"\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', re.IGNORECASE)\n",
    "\n",
    "\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\",\n",
    "            \"Trail\", \"Parkway\", \"Plaza\", \"Park\"]\n",
    "\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "def print_sorted_dic(d):\n",
    "    keys = d.keys()\n",
    "    keys = sorted(keys, key=lambda s: s.lower())\n",
    "    for k in keys:\n",
    "        v = d[k]\n",
    "        print(\"%s: %d\" % (k, v))\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit():\n",
    "\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(OSMFILE, events=(\"start\",)):\n",
    "        if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    pprint.pprint(dict(street_types))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    audit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridgeline Drive West => Ridgeline Drive West\n",
      "Gulf Road West => Gulf Road West\n",
      "North Dartmouth Mall => North Dartmouth Mall\n",
      "Elihu Way => Elihu Way\n",
      "Soules Way => Soules Way\n",
      "Flores Way => Flores Way\n",
      "Oakstone Way => Oakstone Way\n",
      "Swartzs Way => Swartzs Way\n",
      "Rileys Way => Rileys Way\n",
      "Owls Way => Owls Way\n",
      "Kelseys Way => Kelseys Way\n",
      "Olin Howland Way => Olin Howland Way\n",
      "Jennings Way => Jennings Way\n",
      "Stonehaven Way => Stonehaven Street\n",
      "Melissa Beth Way => Melissa Beth Way\n",
      "Hunters Way => Hunters Way\n",
      "Abner Potters Way => Abner Potters Way\n",
      "Indian Spring Way => Indian Spring Way\n",
      "Nicks Way => Nicks Way\n",
      "Princess Pine Way => Princess Pine Way\n",
      "Fisher Pines Way => Fisher Pines Way\n",
      "Loretta Way => Loretta Way\n",
      "Pine Cone Way => Pine Cone Way\n",
      "Pine Needle Way => Pine Needle Way\n",
      "Elise Michelle Way => Elise Michelle Way\n",
      "Judges Way => Judges Way\n",
      "Cheryl's Way => Cheryl's Way\n",
      "Clydes Way => Clydes Way\n",
      "Willow Way => Willow Way\n",
      "Wildberry Way => Wildberry Way\n",
      "Little Pine Way => Little Pine Way\n",
      "Aimes Way => Aimes Way\n",
      "Jillian Way => Jillian Way\n",
      "Brothers Way => Brothers Way\n",
      "Village Way => Village Way\n",
      "Walters Way => Walters Way\n",
      "Jordans Way => Jordans Way\n",
      "Tootell Way => Tootell Way\n",
      "Grand Pine Way => Grand Pine Way\n",
      "Wen-Eds Way => Wen-Eds Way\n",
      "Maya Way => Maya Way\n",
      "Cedar Dell Way => Cedar Dell Way\n",
      "Spinnaker Way => Spinnaker Way\n",
      "Hersheys Way => Hersheys Way\n",
      "Roller Coaster Way => Roller Coaster Way\n",
      "Hebert Way => Hebert Way\n",
      "Whalers Way => Whalers Way\n",
      "Windward Way => Windward Way\n",
      "Carters Way => Carters Way\n",
      "Bridle Way => Bridle Way\n",
      "Brayton Way => Brayton Way\n",
      "Gels Way => Gels Way\n",
      "Amory Pettey Way => Amory Pettey Way\n",
      "Julius Way => Julius Way\n",
      "Thistle Dew Way => Thistle Dew Way\n",
      "Smiths Way => Smiths Way\n",
      "Attatash Way => Attatash Way\n",
      "Scotts Way => Scotts Way\n",
      "Sams Way => Sams Way\n",
      "Allens Pond => Allens Pond\n",
      "Hobbitt Hill Path => Hobbitt Hill Path\n",
      "Woodcart Path => Woodcart Path\n",
      "Swan Pond Path => Swan Pond Path\n",
      "White Oak Run => White Oak Run\n",
      "Blue Heron Run => Blue Heron Run\n",
      "Bent Oak Run => Bent Oak Run\n",
      "Least Tern Circle => Least Tern Circle\n",
      "Captains Circle => Captains Circle\n",
      "Brushwood Circle => Brushwood Circle\n",
      "Christopher Circle => Christopher Circle\n",
      "Horseneck Road East => Horseneck Road East\n",
      "American Legion Highway => American Legion Highway\n",
      "Hillcrest Acres => Hillcrest Acres\n",
      "Charlotte White Road Extension => Charlotte White Road Extension\n",
      "Boathouse Row => Boathouse Row\n",
      "Hawks Nest Ridge => Hawks Nest Ridge\n"
     ]
    }
   ],
   "source": [
    "mapping = {\"St\": \"Street\",\n",
    "           \"ST\": \"Street\",\n",
    "           \"St.\": \"Street\",\n",
    "           \"St,\": \"Street\",\n",
    "           \"Street.\": \"Street\",\n",
    "           \"street\": \"Street\",\n",
    "           \"Sq\": \"Square\",\n",
    "           \"Rd.\": \"Road\",\n",
    "           \"Rd\": \"Road\",\n",
    "           \"Ave\": \"Avenue\",\n",
    "           \"DR.\": \"Drive\"\n",
    "           }\n",
    "\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            street_types[street_type].add(street_name)\n",
    "\n",
    "\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "\n",
    "def audit(osmfile):\n",
    "    osm_file = open(osmfile, \"r\")\n",
    "    street_types = defaultdict(set)\n",
    "    for event, elem in ET.iterparse(osmfile, events=(\"start\",)):\n",
    "\n",
    "        if elem.tag == \"way\":\n",
    "            for tag in elem.iter(\"tag\"):\n",
    "                if is_street_name(tag):\n",
    "                    audit_street_type(street_types, tag.attrib['v'])\n",
    "    osm_file.close()\n",
    "    return street_types\n",
    "\n",
    "\n",
    "def update_name(name, mapping):\n",
    "    for key, value in mapping.items():\n",
    "        if re.search(key, name):\n",
    "            name = re.sub(street_type_re, value, name)\n",
    "\n",
    "    return name\n",
    "\n",
    "\n",
    "def test():\n",
    "    st_types = audit(OSMFILE)\n",
    "    for st_type, ways in st_types.items():\n",
    "        for name in ways:\n",
    "            better_name = update_name(name, mapping)\n",
    "            print (name, \"=>\", better_name)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_schema.py\n",
    "\n",
    "SCHEMA = {\n",
    "    'node': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'lat': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'lon': {'required': True, 'type': 'float', 'coerce': float},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'node_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "            'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'user': {'required': True, 'type': 'string'},\n",
    "            'uid': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'version': {'required': True, 'type': 'string'},\n",
    "            'changeset': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "            'timestamp': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_nodes': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'node_id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'position': {'required': True, 'type': 'integer', 'coerce': int}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'way_tags': {\n",
    "        'type': 'list',\n",
    "        'schema': {\n",
    "            'type': 'dict',\n",
    "            'schema': {\n",
    "                'id': {'required': True, 'type': 'integer', 'coerce': int},\n",
    "                'key': {'required': True, 'type': 'string'},\n",
    "                'value': {'required': True, 'type': 'string'},\n",
    "                'type': {'required': True, 'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SCHEMA' from 'my_schema' (C:\\Users\\wille\\my_schema.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-4f19d06919a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmy_schema\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSCHEMA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[0mOSM_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"WPM\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'SCHEMA' from 'my_schema' (C:\\Users\\wille\\my_schema.py)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "After auditing is complete the next step is to prepare the data to be inserted into a SQL database.\n",
    "To do so you will parse the elements in the OSM XML file, transforming them from document format to\n",
    "tabular format, thus making it possible to write to .csv files.  These csv files can then easily be\n",
    "imported to a SQL database as tables.\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Utilize a schema and validation library to ensure the transformed data is in the correct format\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "We've already provided the code needed to load the data, perform iterative parsing and write the\n",
    "output to csv files. Your task is to complete the shape_element function that will transform each\n",
    "element into the correct format. To make this process easier we've already defined a schema (see\n",
    "the schema.py file in the last code tab) for the .csv files and the eventual tables. Using the \n",
    "cerberus library we can validate the output against this schema to ensure it is correct.\n",
    "\n",
    "## Shape Element Function\n",
    "The function should take as input an iterparse Element object and return a dictionary.\n",
    "\n",
    "### If the element top level tag is \"node\":\n",
    "The dictionary returned should have the format {\"node\": .., \"node_tags\": ...}\n",
    "\n",
    "The \"node\" field should hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- user\n",
    "- uid\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"node_tags\" field should hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains problematic characters, the tag should be ignored\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" should be set as the tag type\n",
    "  and characters after the \":\" should be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they should be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  should be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field should just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element should look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'user': 'uboot',\n",
    "          'uid': 26299,\n",
    "       'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary should have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "-  user\n",
    "- uid\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "All other attributes can be ignored\n",
    "\n",
    "The \"way_tags\" field should again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" should hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary should have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element should look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'user': 'chicago-buildings',\n",
    "         'uid': 674454,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import pprint\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "import cerberus\n",
    "import schema\n",
    "\n",
    "from my_schema import SCHEMA\n",
    "\n",
    "OSM_PATH = \"WPM\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "LOWER_COLON = re.compile(r'^([a-z]|_)+:([a-z]|_)+')\n",
    "PROBLEMCHARS = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')\n",
    "\n",
    "SCHEMA = schema.SCHEMA\n",
    "\n",
    "# Make sure the fields order in the csvs matches the column order in the sql table schema\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'user', 'uid', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element, node_attr_fields=NODE_FIELDS, way_attr_fields=WAY_FIELDS,\n",
    "                  problem_chars=PROBLEMCHARS, default_tag_type='regular'):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = []  # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    # Fix data issues, based on auditing results\n",
    "\n",
    "    # Shape elements, by splitting the attribute fields per the rules described in the\n",
    " \n",
    "    if element.tag == 'node':\n",
    "\n",
    "            for node_field in node_attr_fields:\n",
    "                node_attribs[node_field] =element.attrib[node_field]\n",
    "\n",
    "            for tag in element.iter('tag'):\n",
    "                k = tag.attrib['k']\n",
    "\n",
    "                # ignores tags containing problem characters in the k tag attribute:\n",
    "\n",
    "                if re.search(PROBLEMCHARS,k):\n",
    "                    continue\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "                tag_dict = {}\n",
    "\n",
    "                tag_dict['id'] = node_attribs['id']\n",
    "\n",
    "                colon_find = re.split('[:]', k)\n",
    "\n",
    "                if len(colon_find) == 1:\n",
    "\n",
    "                    tag_dict['key'] = k\n",
    "                    tag_dict['type'] = 'regular'\n",
    "\n",
    "                elif len(colon_find) == 2:\n",
    "\n",
    "                    tag_dict['key'] = colon_find[1]\n",
    "                    tag_dict['type'] = colon_find[0]\n",
    "\n",
    "                elif len(colon_find) > 2:\n",
    "\n",
    "                    tag_dict['key'] = ':'.join(colon_find[1:])\n",
    "                    tag_dict['type'] = colon_find[0]\n",
    "\n",
    "                tag_dict['value'] = tag.attrib['v']\n",
    "\n",
    "                tags.append(tag_dict)\n",
    "\n",
    "            return {'node': node_attribs, 'node_tags': tags}\n",
    "\n",
    "    elif element.tag == 'way':\n",
    "\n",
    "        for way_field in way_attr_fields:\n",
    "            way_attribs[way_field] =element.attrib[way_field]\n",
    "\n",
    "        for tag in element.iter('tag'):\n",
    "            k = tag.attrib['k']\n",
    "\n",
    "            # ignores tags containing problem characters in the k tag attribute:\n",
    "\n",
    "            if re.search(PROBLEMCHARS,k):\n",
    "                print (\"Problem character found - skipping element\")\n",
    "                continue\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            tag_dict = {}\n",
    "\n",
    "            tag_dict['id'] = way_attribs['id']\n",
    "\n",
    "            colon_find = re.split('[:]', k)\n",
    "\n",
    "            if len(colon_find) == 1:\n",
    "\n",
    "                tag_dict['key'] = k\n",
    "                tag_dict['type'] = 'regular'\n",
    "\n",
    "            elif len(colon_find) == 2:\n",
    "\n",
    "                tag_dict['key'] = colon_find[1]\n",
    "                tag_dict['type'] = colon_find[0]\n",
    "\n",
    "            elif len(colon_find) > 2:\n",
    "\n",
    "                tag_dict['key'] = ':'.join(colon_find[1:])\n",
    "                tag_dict['type'] = colon_find[0]\n",
    "\n",
    "            tag_dict['value'] = tag.attrib['v']\n",
    "\n",
    "            tags.append(tag_dict)\n",
    "\n",
    "        n = 0\n",
    "        for nd in element.iter('nd'):\n",
    "\n",
    "            nd_dict = {}\n",
    "\n",
    "            nd_dict['id'] = way_attribs['id']\n",
    "            nd_dict['node_id'] = nd.attrib['ref']\n",
    "            nd_dict['position'] = n\n",
    "            way_nodes.append(nd_dict)\n",
    "            n+=1\n",
    "\n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "def validate_element(element, validator, schema=SCHEMA):\n",
    "    \"\"\"Raise ValidationError if element does not match schema\"\"\"\n",
    "    if validator.validate(element, schema) is not True:\n",
    "        field, errors = next(validator.errors.iteritems())\n",
    "        message_string = \"\\nElement of type '{0}' has the following errors:\\n{1}\"\n",
    "        error_string = pprint.pformat(errors)\n",
    "        \n",
    "        raise Exception(message_string.format(field, error_string))\n",
    "\n",
    "\n",
    "class UnicodeDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Extend csv.DictWriter to handle Unicode input\"\"\"\n",
    "\n",
    "    def writerow(self, row):\n",
    "        super(UnicodeDictWriter, self).writerow({\n",
    "            k: (v.encode('utf-8') if isinstance(v, unicode) else v) for k, v in row.iteritems()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in, validate):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w') as way_tags_file:\n",
    "\n",
    "        nodes_writer = UnicodeDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = UnicodeDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = UnicodeDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = UnicodeDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = UnicodeDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        validator = cerberus.Validator()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if validate is True:\n",
    "                    validate_element(el, validator)\n",
    "\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Note: Validation is ~ 10X slower. For the project consider using a small\n",
    "    # sample of the map when validating.\n",
    "    process_map(OSM_PATH, validate=True)\n",
    "    print(\"Reshaped and exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
